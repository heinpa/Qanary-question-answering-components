version: '3'
services:
  mt-helsinki-nlp: 
    image: heipa/qanary-component-helsinki:thesis
    build: # for building from source
      context: .
      dockerfile: Dockerfile
    # or use image: qanary/qanary-component-mt-python-opusmt:latest
    network_mode: host # or use ports
    env_file:
      - .env
    volumes:
      - /home/caspier/.cache/huggingface:/root/.cache/huggingface # for caching huggingface models
